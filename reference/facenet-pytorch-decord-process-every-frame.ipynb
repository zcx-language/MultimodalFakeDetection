{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with facenet-pytorch and decord\n",
    "\n",
    "As of version 2.2, the MTCNN module of facenet-pytorch can work directly with images represented as numpy arrays. This change achieves higher performance when reading video frames with either `cv2.VideoCapture` or `decord.VideoReader` as it avoids conversion to PIL format. A number of additional enhancements have been added to improve detection efficiency.\n",
    "\n",
    "**This notebook demonstrates how to detect every face in every frame in every video of the dataset at full resolution in approximately 3 hours.**\n",
    "\n",
    "---\n",
    "\n",
    "**UPDATE (2020-03-04):** Video reading has been switched from cv2 to decord for improved performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install facenet-pytorch (with internet use \"pip install facenet-pytorch\")\n",
    "!pip install /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.2.9-py3-none-any.whl\n",
    "!cp /kaggle/input/decord/install.sh . && chmod  +x install.sh && ./install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0,'/kaggle/working/reader/python')\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import cupy\n",
    "from decord import VideoReader, gpu\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FastMTCNN Class\n",
    "\n",
    "The following class implements a strided version of MTCNN. See [here](https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution) for the original implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastMTCNN(object):\n",
    "    \"\"\"Fast MTCNN implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, stride, *args, **kwargs):\n",
    "        \"\"\"Constructor for FastMTCNN class.\n",
    "        \n",
    "        Arguments:\n",
    "            stride (int): The detection stride. Faces will be detected every `stride` frames\n",
    "                and remembered for `stride-1` frames.\n",
    "        \n",
    "        Keyword arguments:\n",
    "            resize (float): Fractional frame scaling. [default: {1}]\n",
    "            *args: Arguments to pass to the MTCNN constructor. See help(MTCNN).\n",
    "            **kwargs: Keyword arguments to pass to the MTCNN constructor. See help(MTCNN).\n",
    "        \"\"\"\n",
    "        self.stride = stride\n",
    "        self.mtcnn = MTCNN(*args, **kwargs)\n",
    "        \n",
    "    def __call__(self, frames):\n",
    "        \"\"\"Detect faces in frames using strided MTCNN.\"\"\"\n",
    "                      \n",
    "        boxes, probs = self.mtcnn.detect(frames[::self.stride])\n",
    "\n",
    "        faces = []\n",
    "        probs_out = []\n",
    "        frame_index = []\n",
    "        for i, frame in enumerate(frames):\n",
    "            box_ind = int(i / self.stride)\n",
    "            if boxes[box_ind] is None:\n",
    "                continue\n",
    "            for box, prob in zip(boxes[box_ind], probs[box_ind]):\n",
    "                box = [int(b) for b in box]\n",
    "                faces.append(frame[box[1]:box[3], box[0]:box[2]].copy())\n",
    "                probs_out.append(prob)\n",
    "                frame_index.append(i)\n",
    "                \n",
    "        \n",
    "        return faces, probs, frame_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define face detector\n",
    "\n",
    "The following face detector can detect all faces in a video in approximately 2.8 seconds, allowing all videos in the public test set to be processed in 2.8 * 4000 = 11200 seconds = 3.1 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_mtcnn = FastMTCNN(\n",
    "    stride=10,\n",
    "    margin=20,\n",
    "    factor=0.6,\n",
    "    keep_all=True,\n",
    "    device=device,\n",
    "    thresholds=[0.6, 0.7, 0.98]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1e2038d32d42b59c74c9597c828ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 14min 3s, sys: 9min 33s, total: 23min 37s\n",
      "Wall time: 22min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def mean_detection_prob(prob):\n",
    "    cnt_p = 0\n",
    "    sum_p = 0\n",
    "    for p in prob:\n",
    "        for pp in p:\n",
    "            if pp is not None:\n",
    "                cnt_p += 1\n",
    "                sum_p += pp\n",
    "    return sum_p / cnt_p\n",
    "\n",
    "\n",
    "def get_frames(filename, batch_size=30):\n",
    "    v_cap = VideoReader(filename, ctx=gpu())\n",
    "    v_len = len(v_cap)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, v_len, batch_size):\n",
    "        batch = v_cap.get_batch(range(i, min(i + batch_size, v_len - 1))).asnumpy()\n",
    "        frames.extend(batch.copy())\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    \n",
    "    del v_cap, v_len, batch\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "filenames = glob.glob('/kaggle/input/deepfake-detection-challenge/test_videos/*.mp4')\n",
    "\n",
    "num_faces = 0\n",
    "probs = []\n",
    "indexes = []\n",
    "pbar = tqdm(filenames)\n",
    "for filename in pbar:\n",
    "    frames = get_frames(filename)\n",
    "\n",
    "    faces, prob, index = fast_mtcnn(frames)        \n",
    "    probs.append(mean_detection_prob(prob))\n",
    "\n",
    "    num_faces += len(faces)\n",
    "    pbar.set_description(f'Faces found: {num_faces}')\n",
    "\n",
    "    del frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iorbtaarte.mp4</td>\n",
       "      <td>0.295694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vnlzxqwthl.mp4</td>\n",
       "      <td>0.255125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gqnaxievjx.mp4</td>\n",
       "      <td>0.540020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sjkfxrlxxs.mp4</td>\n",
       "      <td>0.546456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eppyqpgewp.mp4</td>\n",
       "      <td>0.399687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>pxjkzvqomp.mp4</td>\n",
       "      <td>0.261632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>rnfcjxynfa.mp4</td>\n",
       "      <td>0.296991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>hxwtsaydal.mp4</td>\n",
       "      <td>0.564269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>bzvzpwrabw.mp4</td>\n",
       "      <td>0.533757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>mwwploizlj.mp4</td>\n",
       "      <td>0.756997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename     label\n",
       "0    iorbtaarte.mp4  0.295694\n",
       "1    vnlzxqwthl.mp4  0.255125\n",
       "2    gqnaxievjx.mp4  0.540020\n",
       "3    sjkfxrlxxs.mp4  0.546456\n",
       "4    eppyqpgewp.mp4  0.399687\n",
       "..              ...       ...\n",
       "395  pxjkzvqomp.mp4  0.261632\n",
       "396  rnfcjxynfa.mp4  0.296991\n",
       "397  hxwtsaydal.mp4  0.564269\n",
       "398  bzvzpwrabw.mp4  0.533757\n",
       "399  mwwploizlj.mp4  0.756997\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADIFJREFUeJzt3X2MZfccx/H3lxJBUXa2WXRMySpL0Jg0Ev9UPGRVaMVDuglpYxmEIvyhQUL4wyI0Eo1k0XQjlAZNF/VQq82GWLHL0q6mSm1ZbbqthyDiofX1xz2VyfTO3HOf7/3u+5Xc3HPPnJn7mbNnP/nNufd3T2QmkqT594BpB5AkjYaFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVMRJk3yyTZs25dLS0iSfUpLm3qFDh+7OzIVe20200JeWljh48OAkn1KS5l5E3NZmO0+5SFIRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRE50pKi1d/M0Nv35010smlESqxxG6JBVhoUtSERa6JBVhoUtSERa6JBVhoUtSERa6JBVhoUtSEU4sUhlOWtKJzhG6JBVhoUtSERa6JBVhoUtSERa6JBXRs9Aj4rSIuC4iboqIIxHx9mb9oyPi2oi4pbk/ZfxxJUnraTNCvwd4V2Y+FXgO8JaI2AZcDOzLzK3AvuaxJGlKehZ6Zt6RmT9tlv8G3AQ8DjgX2NNstgc4b1whJUm99XUOPSKWgDOBHwOnZuYd0Cl9YPOow0mS2ms9UzQiHg58FXhHZv41Itp+3wqwArC4uDhIRp1AnO0pDa7VCD0iHkSnzL+QmV9rVt8ZEVuar28Bjnf73szcnZnLmbm8sLAwisySpC7avMslgM8BN2XmJ1Z9aS9wQbN8AXD16ONJktpqc8rlucBrgRsi4nCz7j3ALuDKiNgJ/A541XgiSpLa6FnomfkDYL0T5s8fbRxJ0qCcKSpJRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRbS+YpFGz6vzSBolR+iSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVIQzRYtyFqp04nGELklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVIQTizRyvSY1zaJhMztRS7PAEbokFWGhS1IRFrokFWGhS1IRFrokFdGz0CPisog4HhE3rlr3gYj4Q0Qcbm7njDemJKmXNiP0y4HtXdZfkpnPam7XjDaWJKlfPQs9M/cDf5pAFknSEIY5h/7WiPhFc0rmlJElkiQNZNCZop8GPgRkc/9x4HXdNoyIFWAFYHFxccCnk4Y3jzNYqxrm38JZuesbaISemXdm5r2Z+V/gM8BZG2y7OzOXM3N5YWFh0JySpB4GKvSI2LLq4cuBG9fbVpI0GT1PuUTEFcDZwKaIOAa8Hzg7Ip5F55TLUeCNY8woSWqhZ6Fn5o4uqz83hiySpCE4U1SSirDQJakIC12SirDQJakIL0F3gtpoYocTN6T55Ahdkoqw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCCcWDaniVXB6/U5OPJJmkyN0SSrCQpekIix0SSrCQpekIix0SSrCQpekIix0SSrCQpekIix0SSrCmaItTGs2qDM2JfXDEbokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRTiyi5mXkqvLfanScuFaPI3RJKsJCl6QiLHRJKsJCl6QiLHRJKqJnoUfEZRFxPCJuXLXu0RFxbUTc0tyfMt6YkqRe2ozQLwe2r1l3MbAvM7cC+5rHkqQp6lnombkf+NOa1ecCe5rlPcB5I84lSerToOfQT83MOwCa+82jiyRJGsTYXxSNiJWIOBgRB++6665xP50knbAGLfQ7I2ILQHN/fL0NM3N3Zi5n5vLCwsKATydJ6mXQQt8LXNAsXwBcPZo4kqRBtXnb4hXAj4AzIuJYROwEdgEvjIhbgBc2jyVJU9Tz0xYzc8c6X3r+iLNIkobgTFFJKsJCl6QiLHRJKsJCl6QivASd+uZl4DRNwxx/1S+r5whdkoqw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCCcWSepbr8k91SfwzCpH6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhDNFJXVV8VKD1We4OkKXpCIsdEkqwkKXpCIsdEkqwkKXpCIsdEkqwkKXpCIsdEkqwolF0phVn8yi2eEIXZKKsNAlqQgLXZKKsNAlqQgLXZKKGOpdLhFxFPgbcC9wT2YujyKUJKl/o3jb4vMy8+4R/BxJ0hA85SJJRQxb6Al8NyIORcTKKAJJkgYTmTn4N0c8NjNvj4jNwLXARZm5f802K8AKwOLi4rNvu+22YfKORcVLbenE0GuWqcd2f2Z11m5EHGrzGuVQI/TMvL25Pw5cBZzVZZvdmbmcmcsLCwvDPJ0kaQMDF3pEPCwiTr5vGXgRcOOogkmS+jPMu1xOBa6KiPt+zhcz89sjSSVJ6tvAhZ6ZtwLPHGEWSdIQfNuiJBVhoUtSERa6JBVhoUtSESfEJeicXKGqPLa1miN0SSrCQpekIix0SSrCQpekIix0SSrCQpekIix0SSrCQpekIix0SSrihJgpKkltbDTzdlYvT7eaI3RJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKsJCl6QiLHRJKmJurli00ZVEYD6uJiJpfvXqoF4m0VGO0CWpCAtdkoqw0CWpCAtdkoqw0CWpiKEKPSK2R8TNEfHriLh4VKEkSf0buNAj4oHApcCLgW3AjojYNqpgkqT+DDNCPwv4dWbempn/Br4EnDuaWJKkfg1T6I8Dfr/q8bFmnSRpCoaZKRpd1uX9NopYAVaah3+PiJuHeM5NwN1dw3xkiJ86fuvmngPzmt3ckzev2SeSe8iOekKbjYYp9GPAaasePx64fe1Gmbkb2D3E8/xfRBzMzOVR/KxJmtfcML/ZzT1585p9XnN3M8wpl58AWyPi9Ih4MHA+sHc0sSRJ/Rp4hJ6Z90TEW4HvAA8ELsvMIyNLJknqy1CftpiZ1wDXjChLGyM5dTMF85ob5je7uSdvXrPPa+77icz7vY4pSZpDTv2XpCJmstB7faRARLwzIn4ZEb+IiH0R0eotPePWIvebIuKGiDgcET+YlZm1bT/CISJeGREZETPzjoAW+/zCiLir2eeHI+L108i5Vpt9HhGvbo7zIxHxxUln7KbF/r5k1b7+VUT8ZRo5u2mRfTEirouInzXdcs40cg4lM2fqRucF1t8ATwQeDPwc2LZmm+cBD22W3wx8eU5yP2LV8suAb89D7ma7k4H9wAFgedq5+9jnFwKfmnbWAXJvBX4GnNI83jwPuddsfxGdN0vMyz7fDby5Wd4GHJ127n5vszhC7/mRApl5XWb+o3l4gM574KetTe6/rnr4MLpMxJqCth/h8CHgo8A/Jxmuh3n9+Ik2ud8AXJqZfwbIzOMTzthNv/t7B3DFRJL11iZ7Ao9olh9Jl3k1s24WC73fjxTYCXxrrInaaZU7It4SEb+hU45vm1C2jfTMHRFnAqdl5jcmGayFtsfKK5o/ob8SEad1+fqktcn9ZODJEfHDiDgQEdsnlm59rf9vNqdBTwe+P4FcbbTJ/gHgNRFxjM679y6aTLTRmcVCb/WRAgAR8RpgGfjYWBO10yp3Zl6amU8C3g28b+ypetswd0Q8ALgEeNfEErXXZp9/HVjKzGcA3wP2jD1Vb21yn0TntMvZdEa6n42IR405Vy+t/2/SmWj4lcy8d4x5+tEm+w7g8sx8PHAO8Pnm+J8bsxi21UcKRMQLgPcCL8vMf00o20Za5V7lS8B5Y03UTq/cJwNPB66PiKPAc4C9M/LCaM99npl/XHV8fAZ49oSybaTNsXIMuDoz/5OZvwVuplPw09TPMX4+s3O6Bdpl3wlcCZCZPwIeQudzXubHtE/id3nx4iTgVjp/rt334sXT1mxzJp0XOLZOO2+fubeuWn4pcHAecq/Z/npm50XRNvt8y6rllwMH5iT3dmBPs7yJzumCx8x67ma7M4CjNPNcZuHWcp9/C7iwWX4qncKfmd+h1e857QDr7PxzgF81pf3eZt0H6YzGofOn853A4ea2d9qZW+b+JHCkyXzdRsU5S7nXbDszhd5yn3+42ec/b/b5U6aduWXuAD4B/BK4ATh/2pnbHit0zkXvmnbWAfb5NuCHzbFyGHjRtDP3e3OmqCQVMYvn0CVJA7DQJakIC12SirDQJakIC12SirDQJakIC12SirDQJamI/wGqA68ZgUFgwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = np.asarray(probs)\n",
    "probs = np.clip((1 - probs) ** (1 / 6) * 1.7, 0.0, 1.0)\n",
    "plt.hist(probs, 40);\n",
    "\n",
    "filenames = [os.path.basename(f) for f in filenames]\n",
    "\n",
    "submission = pd.DataFrame({'filename': filenames, 'label': probs})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2eb3012695444a2d800aeab346c64b93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "399b6fbf2b524720bc17c89c7b29db1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_970f1b079576415eb074f78b992858bf",
       "placeholder": "​",
       "style": "IPY_MODEL_91c2e806d8fe493b94827142df3a8b53",
       "value": " 400/400 [22:17&lt;00:00,  3.34s/it]"
      }
     },
     "4be6770ca60e4f3b85c2ebe947e9b228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "592a9898b595439297b408f25fe28c0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a836aaba1944042955e16caa41ba974": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Faces found: 116883: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_592a9898b595439297b408f25fe28c0e",
       "max": 400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4be6770ca60e4f3b85c2ebe947e9b228",
       "value": 400
      }
     },
     "91c2e806d8fe493b94827142df3a8b53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "970f1b079576415eb074f78b992858bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc1e2038d32d42b59c74c9597c828ab3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6a836aaba1944042955e16caa41ba974",
        "IPY_MODEL_399b6fbf2b524720bc17c89c7b29db1f"
       ],
       "layout": "IPY_MODEL_2eb3012695444a2d800aeab346c64b93"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
